{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "import mglearn\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris,make_moons,make_blobs,make_regression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (confusion_matrix,precision_score,recall_score,f1_score,\n",
    "    roc_curve,roc_auc_score,precision_recall_curve,accuracy_score,classification_report,mean_squared_error,r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple linear regression problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=make_regression(n_samples=1000, n_features=1,noise=10.0)\n",
    "\n",
    "plt.scatter(X,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LinearRegression().fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X)\n",
    "\n",
    "plt.scatter(X,y,alpha=0.1)\n",
    "plt.scatter(X,y_pred,color='red',s=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean squared error: {}\".format(mean_squared_error(y,y_pred)))\n",
    "print(\"R2 score: {}\".format(r2_score(y,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescaling the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=0.01*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LinearRegression().fit(X,y)\n",
    "y_pred=model.predict(X)\n",
    "\n",
    "plt.scatter(X,y,alpha=0.1)\n",
    "plt.scatter(X,y_pred,color='red',s=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean squared error: {}\".format(mean_squared_error(y,y_pred)))\n",
    "print(\"R2 score: {}\".format(r2_score(y,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the synthetic 'moons' data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=1000, noise=0.25, random_state=4)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, stratify=y)\n",
    "mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the performance of SVM classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_svm = SVC(kernel='rbf', gamma=0.1).fit(X_train,y_train)\n",
    "predictions = kernel_svm.predict(X_test)\n",
    "print(\"Confusion matrix:  \\n{}\\n\".format(confusion_matrix(y_test,predictions)))\n",
    "print(\"Precision: \\n{}\\n\".format(precision_score(y_test,predictions,pos_label=1)))\n",
    "print(\"Recall: \\n{}\\n\".format(recall_score(y_test,predictions,pos_label=1)))\n",
    "print(\"F1: \\n{}\".format(f1_score(y_test,predictions,pos_label=1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now looking at the ROC curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fprSVM,tprSVM,thresh = roc_curve(y_test,kernel_svm.decision_function(X_test))\n",
    "plt.plot(fprSVM,tprSVM)\n",
    "print(\"Area under curve: \\n{}\".format(roc_auc_score(y_test,kernel_svm.decision_function(X_test))) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** try some other classifier(s) on this dataset, and compare their ROC-curves. Do you find a classifier that strictly dominates  another in the sense that its ROC curve is always above the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part 3: Multiclass Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing the confusion matrix from the slides from imaginary true and predicted label arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truelabels = np.arange(220)\n",
    "truelabels[0:100]=1\n",
    "truelabels[100:110]=2\n",
    "truelabels[110:120]=3\n",
    "truelabels[120:220]=4\n",
    "predlabels = np.arange(220)\n",
    "predlabels[0:89]=1\n",
    "predlabels[89:93]=2\n",
    "predlabels[93:97]=3\n",
    "predlabels[97:100]=4\n",
    "predlabels[100:103]=2\n",
    "predlabels[103:106]=3\n",
    "predlabels[106:110]=4\n",
    "predlabels[110:112]=1\n",
    "predlabels[112:120]=3\n",
    "predlabels[120:121]=1\n",
    "predlabels[121:122]=3\n",
    "predlabels[122:220]=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix:  \\n{}\\n\".format(confusion_matrix(truelabels,predlabels)))\n",
    "print(\"Accuracy: \\n{}\\n\".format(accuracy_score(truelabels,predlabels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the averaged binary scores:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"One-vs-all measures: \\n{}\\n\".format(classification_report(truelabels,predlabels)))\n",
    "print(\"Macro average F1: \\n{}\\n\".format(f1_score(truelabels,predlabels,average='macro')))\n",
    "print(\"Micro average F1: \\n{}\\n\".format(f1_score(truelabels,predlabels,average='micro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a fairly big sample from the make_moons data generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=30000, noise=0.25, random_state=3)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, stratify=y, random_state=42)\n",
    "mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn a Naive Bayes and a Neural network model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=[10],activation='tanh',solver='lbfgs', max_iter=2000, random_state=0).fit(X_train, y_train)\n",
    "nb = GaussianNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct histograms showing the distribution of probability predictions for the positive class. Histograms that are more concentrated at the extreme ends represent classifiers that are more 'confident' in their predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(mlp.predict_proba(X_test))\n",
    "nnposprobas=mlp.predict_proba(X_test)[:,1]\n",
    "nbposprobas=nb.predict_proba(X_test)[:,1]\n",
    "pddf = pd.DataFrame({'NN' : nnposprobas, 'NB' : nbposprobas})\n",
    "pddf.plot.hist(bins=20,alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distribution says nothing about calibration. For that we create a graph that plots the value *b* of the predicted probability for the positive class against the ratio of actually positive datapoints in the small interval (*b*,*b+binwidth*). We also plot a relative measure for how many datapoints fall into each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posprobas=nbposprobas\n",
    "posprobas=nnposprobas\n",
    "\n",
    "\n",
    "binwidth=0.05\n",
    "bins = np.arange(0,1,binwidth)\n",
    "\n",
    "for posprobas,label in zip( (nbposprobas,nnposprobas),(\"Naive Bayes\",\"Neural Net\")  ):\n",
    "    predperc = np.zeros(bins.size)\n",
    "    binexamples = np.zeros(bins.size)\n",
    "    \n",
    "    for i,b in enumerate(bins):\n",
    "        preds = y_test[(posprobas >= b) & (posprobas < b+binwidth) ]\n",
    "        predperc[i] = np.sum(preds)/preds.size\n",
    "        binexamples[i]=preds.size\n",
    "        \n",
    "    binexamples*=1/np.max(binexamples)\n",
    "        \n",
    "    plt.plot(bins,predperc,label=\"Pos. ratio \"+label)\n",
    "    plt.plot(bins,binexamples,label=\"Num.pred. \"+label)\n",
    "plt.plot(bins,bins)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that both naive Bayes and neural network here are fairly well calibrated. Due to the relatively small number of cases with predicted probabilities in the middle range, there are some fluctuations in the positive ratios here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
