{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data models and analyses techniques: Exercise sheet 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Your name:* [Please write your name here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "For each lecture there will be a collection of exercises presented as Jupyter notebooks. The exercises should be solved and documented as a mini-project that will form the basis for the examination. When solving the exercises it is therefore important that you \n",
    " * document all relevant results and analyses that you have obtained/performed during the exercises.\n",
    " * try to relate your results to the theoretical background of the methods being applied. \n",
    "\n",
    "The documentation should be integrated (by adding new code/markdown cells) in the Jupyter notebooks containing the exercise sheets.\n",
    "\n",
    "The mini-project should be delivered after the last seminar in this module (an exact date will be provided later) and should consist of:\n",
    " - a single pdf-file containing all the notebooks; the 'File' menu gives you the option of downloading a pdf-version of your notebook. The name of the file should be [your\\_first\\_name]_[your\\_family\\_name].pdf (e.g. Thomas\\_Nielsen.pdf).\n",
    " - a copy of your notebooks with the solutions to the exercises. The notebooks should be named [your\\_first name]\\_[your\\_family\\_name]\\_[exercise\\_sheet\\_number].ipynb (e.g., Thomas\\_Nielsen\\_1.ipnyb).\n",
    " \n",
    "If you have any questions about the exercises, you are strongly encouraged to post you questions on the MS Teams channel or on the discussion forum on Moodle.\n",
    "\n",
    "Last, but not least:\n",
    "* Looking for an overview of the markdown language? The cheat sheet <a href=\"https://medium.com/ibm-data-science-experience/markdown-for-jupyter-notebooks-cheatsheet-386c05aeebed\">here</a> might help.\n",
    "* For the Python specific components of the exercises, you should not need constructs beyond those that are already included in the notebooks on the course's web-page (still you should not feel constrained by these, so feel free to be adventurous). You may, however, need to consult the documentation for some of the methods supplied by `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data source\n",
    "\n",
    "In this exercise we will play around with the a subset of the Boston housing data set, which is available at `http://lib.stat.cmu.edu/datasets/boston`. The data is unfortunately not available through sklearn, so instead we will have to download and massage it a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "url = 'http://lib.stat.cmu.edu/datasets/boston'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Get the content of the response as a string and split into lines\n",
    "    lines = response.text.splitlines()\n",
    "    meta = \"\\n\".join(lines[0:21])\n",
    "    \n",
    "    # Drop lines with meta data\n",
    "    lines = lines[22:]\n",
    "    \n",
    "    # Column names\n",
    "    col_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "\n",
    "    # Join every two lines (rows are broken over two lines)\n",
    "    combined_lines = []\n",
    "    for i in range(0, len(lines), 2):\n",
    "        combined_line = lines[i].strip() + \" \" + lines[i + 1].strip()\n",
    "        combined_lines.append(combined_line)\n",
    "\n",
    "    # Combine all lines into a single string\n",
    "    s = \"\\n\".join(combined_lines)\n",
    "    \n",
    "    # Read into a DataFrame using StringIO\n",
    "    df = pd.read_csv(StringIO(s), delim_whitespace=True, header=None, names=col_names)\n",
    "\n",
    "    # Drop column B\n",
    "    df = df.drop(columns=['B'])    \n",
    "\n",
    "    data = {}\n",
    "    data['DESCR'] = meta\n",
    "    data['target'] = df['MEDV']\n",
    "    data['data'] = df.drop(columns=['MEDV'])\n",
    "    data['feature_names'] = data['data']\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to retrieve data: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The variables in the data set\n",
    "data['data'].columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... and the target variable with the median value of owner-occupied homes in $1000's\n",
    "data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a bit acquainted with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we treat it as a classification problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "c = np.array([1 if y > np.median(data['target']) else 0 for y in data['target']])\n",
    "X_train, X_test, c_train, c_test = train_test_split(data['data'], c, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "data_df = pd.DataFrame(X_train, columns=data['data'].columns.to_list())\n",
    "# Create scatter plot and color by class label.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "_=pd.plotting.scatter_matrix(data_df, c=c_train, figsize=(15, 15), marker='o',\n",
    "                           hist_kwds={'bins': 20}, s=60, alpha=.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise set 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model learning\n",
    "* Learn a decision tree using the training data and evaluate its performance on both the training data and the test data. Generate random training/test partitions or varying sizes and analyze how the accuracy results vary (consult the documentation for `train_test_split(.)`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model analysis\n",
    "\n",
    "* Display the decision tree learned using the training data.\n",
    "* What are the most important features as determined by the learned tree and does, e.g., the choice of top node seem reasonable to you based on your knowledge of the data domain?\n",
    "* How does the features deemed *most important* by the decision tree learner match the generated tree and your understanding of the domain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model complexity\n",
    "* Try controlling the complexity of the learned decision tree by adjusting the parameters max\\_depth, min\\_samples\\_split, min\\_samples\\_leaf\n",
    "* Investigate the effect when changing these parameters:\n",
    "    - Visualize (some of) the trees\n",
    "    - Evaluate the performance of the models on both the training data and the test data\n",
    "* By designating a part of the data as *validation data*, try to automatically find good values for the parameters controlling the size of the tree. How does the obtained parameters match your manual investigation?\n",
    "* Instead of using a validation set, try to find good parameter values using cross-validation. How does the results compare to those that you found above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise set 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we shall expore and compare the k-nearest neighbor classifier and the naive Bayes model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest neighbor\n",
    "* Classify the instances in the test set using default settings for the k-NN classifier.\n",
    "* Try experimenting with different values for 'k'. How do the values affect the classification results? Feel free to try to automate this process using the methods explored in the previous exercise sheet. \n",
    "* Try to get some more insight into the data by generating descriptive statistics and by plotting the data. \n",
    "* Based on your understanding of the data and the properties of the k-NN classifier, does it seem reasonable to try to manipulate the data (e.g. through normalization) or work with different distance metrics in order to improve the performance of the classifier? How does such changes affect classification accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Naive Bayes\n",
    "\n",
    "* Classify the instances in the test set using the naive Bayes model.\n",
    "* The naive Bayes classifier makes the strong assumption that the attributes are conditionally independent given the class variable. Can you identify any pairs of attributes that do not adhere to this assumption, and how does it affect the performance of the classifier if one of the attributes are removed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison\n",
    "\n",
    "* Using the results obtained above, classify the instances in the test set using the k-NN classifier, the naive Bayes classifier, and decision trees.\n",
    "* Based on your intuitive understanding of the classifiers, can you explain their relative performance? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
