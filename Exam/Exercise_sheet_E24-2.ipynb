{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we perform character recognition using SVM and NN classifiers. We use the MNIST dataset, which consists of 70000 handwritten digits 0..9 at a resolution of 28x28 pixels. \n",
    "\n",
    "Stuff we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import sklearn as skl\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the MNIST data. Using the fetch_mldata function, this will be downloaded from the web, and stored in the directory you specify as data_home (replace my path in the following cell):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml(name='mnist_784', data_home='/home/kenneth/Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has .data and .target attributes. The following gives us some basic information on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints: 70000\n",
      "\n",
      "Number of features: 784\n",
      "\n",
      "List of labels: ['0' '1' '2' '3' '4' '5' '6' '7' '8' '9']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of datapoints: {}\\n\".format(mnist.data.shape[0]))\n",
    "print(\"Number of features: {}\\n\".format(mnist.data.shape[1]))\n",
    "print(\"List of labels: {}\\n\".format(np.unique(mnist.target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mnist.data is represented as a Pandas dataframe. The following code expects mnist.data to be a plain np.array, which we get simply by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.data=np.array(mnist.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot individual datapoints as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of datapoint no. 4:\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  55 148 210 253 253 113  87 148\n",
      "  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  87 232 252 253 189 210 252 252 253 168   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   4  57 242 252 190  65   5  12 182\n",
      " 252 253 116   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  96 252 252 183  14   0   0  92 252 252 225  21   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 132 253 252 146  14   0   0   0\n",
      " 215 252 252  79   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0 126 253 247 176   9   0   0   8  78 245 253 129   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  16 232 252 176   0   0   0  36\n",
      " 201 252 252 169  11   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  22 252 252  30  22 119 197 241 253 252 251  77   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  16 231 252 253 252 252\n",
      " 252 226 227 252 231   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  55 235 253 217 138  42  24 192 252 143   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  62 255 253 109   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  71 253 252  21   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0 253 252  21   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  71 253 252\n",
      "  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 106 253 252  21   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  45\n",
      " 255 253  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 218 252  56   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  96 252 189  42   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  14 184 252 170  11   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  14 147 252  42   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n",
      "\n",
      "Target of datapoint no. 4:\n",
      "9\n",
      "\n",
      "As image:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 4\n",
    "print(\"Value of datapoint no. {}:\\n{}\\n\".format(index,mnist.data[index,:]))\n",
    "print(\"Target of datapoint no. {}:\\n{}\\n\".format(index,mnist.target[index])) ## Added the target value of index 4\n",
    "print(\"As image:\\n\")\n",
    "plt.imshow(mnist.data[index].reshape(28,28),cmap=plt.cm.gray_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things a little bit simpler (and faster!), we can extract from the data binary subsets, that only contain the data for two selected digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first datapoint now is: \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7        3\n",
      "10       3\n",
      "12       3\n",
      "15       7\n",
      "27       3\n",
      "        ..\n",
      "69975    3\n",
      "69979    7\n",
      "69986    3\n",
      "69990    7\n",
      "69996    3\n",
      "Name: class, Length: 14434, dtype: category\n",
      "Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "digit0='3'\n",
    "digit1='7'\n",
    "mnist_bin_data=mnist.data[np.logical_or(mnist.target==digit0,mnist.target==digit1)]\n",
    "mnist_bin_target=mnist.target[np.logical_or(mnist.target==digit0,mnist.target==digit1)]\n",
    "print(\"The first datapoint now is: \\n\")\n",
    "plt.imshow(mnist_bin_data[0].reshape(28,28),cmap=plt.cm.gray_r)\n",
    "plt.show()\n",
    "print(mnist_bin_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:** Split the mnist_bin data into training and test set. Learn different SVM and NN models by varying the kernel functions (SVM), the network structure (NN), and the solver (NN). For each configuration, determine the time it takes to learn the model, and the accuracy on the test data. *Caution*: for some configurations, learning here can take a little while (several minutes).\n",
    "\n",
    "Using the numpy where() function, one can extract the indices of the test cases that were misclassified: <br>\n",
    "`misclass = np.where(test != predictions)` <br>\n",
    "Inspect some misclassified cases. Do they correspond to hard to recognize digits (also for the human reader)? \n",
    "\n",
    "How do results (time and accuracy) change, depending on whether you consider an 'easy' binary task (e.g., distinguishing '1' and '0'), or a more difficult one (e.g., '4' vs. '5'). \n",
    "\n",
    "Identify one or several good configurations that give a reasonable combination of accuracy and runtime. Use these configurations to perform a full classification of the 10 classes in the original dataset (after split into train/test). Using `sklearn.metrics.confusion_matrix` you can get an overview of all combinations of true and predicted labels (see p. 298-299 in MÃ¼ller & Guido). What does this tell you about which digits are easy, and which ones are difficult to recognize, and which ones are most easily confused?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exercise: Split the mnist_bin data into training and test set. \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Splitting the data set into a test and train. This only holds 3 and 7, as per split in previous section\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist_bin_data, mnist_bin_target, random_state=1) ## test size 25% and training 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it took to learn the linear kernel model: 3.43 seconds\n",
      "Training Accuracy: 1.00\n",
      "Test Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "## Exercise: Learn different SVM and NN models by varying the kernel functions (SVM), the network structure (NN), and the solver (NN)\n",
    "import time\n",
    "\n",
    "## In the below section we learn a SVM model with a linaers kernel type. We measure the time it takes to learn the model (as is done in the coming sections as well) to know\n",
    "## How long it takes and thence include that when evaluating the performance of the model.\n",
    "\n",
    "kernel_type = 'linear'\n",
    "start=time.time()\n",
    "linear_svm = SVC(kernel=kernel_type).fit(X_train,y_train)\n",
    "end=time.time()\n",
    "elapsed_time=end-start \n",
    "print(f\"Time it took to learn the {kernel_type} kernel model: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Calculate accuracy on training data\n",
    "train_accuracy = linear_svm.score(X_train, y_train)\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "test_accuracy = linear_svm.score(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM linaer model is done in 11 seconds and has a test accurancy of 98% and 100% on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it took to learn the rbf kernel model: 146.94 seconds\n",
      "Training Accuracy: 1.00\n",
      "Test Accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "## Exercise: Learn different SVM and NN models by varying the kernel functions (SVM), the network structure (NN), and the solver (NN)\n",
    "import time\n",
    "\n",
    "## In the next section we learn a SVM model, this time with a rbf kernel type. Gamme is set to 1.0 and not altered during this exercise.\n",
    "\n",
    "\n",
    "kernel_type = 'rbf'\n",
    "start=time.time()\n",
    "kernel_svm = SVC(kernel=kernel_type, gamma=1.0).fit(X_train,y_train)\n",
    "end=time.time()\n",
    "elapsed_time=end-start \n",
    "print(f\"Time it took to learn the {kernel_type} kernel model: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Calculate accuracy on training data\n",
    "train_accuracy = kernel_svm.score(X_train, y_train)\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "test_accuracy = kernel_svm.score(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM model using the rbf kernel takes 475 seconds (approx. 8 min) and get 51% in accurancy on the test data and 100% on the training data.\n",
    "\n",
    "Comparing the two SVM the latter performs poorly (51%) compared to the first (98%). Also the latter takes almost 8 min compared to only 10 seconds in the first model.\n",
    "\n",
    "Next section turns to neural networks - let's see how they perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Precomputed matrix must be a square matrix. Input is a 10825x784 matrix.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m kernel_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m start\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 5\u001b[0m kernel_svm \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39mkernel_type, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[1;32m      6\u001b[0m end\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      7\u001b[0m elapsed_time\u001b[38;5;241m=\u001b[39mend\u001b[38;5;241m-\u001b[39mstart \n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:215\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX and y have incompatible shapes.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m samples, but y has \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_samples, y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    212\u001b[0m     )\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m n_samples \u001b[38;5;241m!=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecomputed matrix must be a square matrix.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Input is a \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124mx\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m matrix.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    218\u001b[0m     )\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m sample_weight\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m n_samples:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight and X have incompatible shapes: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;241m%\u001b[39m (sample_weight\u001b[38;5;241m.\u001b[39mshape, X\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    227\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Precomputed matrix must be a square matrix. Input is a 10825x784 matrix."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import time\n",
    "\n",
    "kernel_type = 'precomputed'\n",
    "start=time.time()\n",
    "kernel_svm = SVC(kernel=kernel_type, gamma=1.0).fit(X_train,y_train)\n",
    "end=time.time()\n",
    "elapsed_time=end-start \n",
    "print(f\"Time it took to learn the {kernel_type} kernel model: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Calculate accuracy on training data\n",
    "train_accuracy = kernel_svm.score(X_train, y_train)\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "test_accuracy = kernel_svm.score(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "This next section is rather expansive, so let's run through the intention.\n",
    "\n",
    "Neural networks can have 0 or more hidden layers. For each layer it's possible to configure the number of nodes. E.g. () denotes no hidden layers (name here), (10, 10, 10) denotes three layers each layer containing to nodes. The construction of the layers and number of nodes is it's architecture.\n",
    "Furthermore it possible to set the activation to a number of variations. Here relu and tanh is used.\n",
    "To find a good model the model iteraters through and tries to find a good (valley) mode. The number of iterations can be set and impacts the model ability to find a convergence point. A model can run out of iterations without being able to converge, which results in a convergence warning.\n",
    "Lastely the solver can also be configured. Here it set to lbfgs and not changed.\n",
    "\n",
    "There is a range of possible configurations and architectures, leaving a number of possible scenarios. The code below build a iterative model, that can be configured to run through different scenarios. The iterative model iterates through the defined architecture and then the activations. Firstly it tries each architecture (e.g. () then (5,), then (10,) and so on) with each activations.\n",
    "\n",
    "The resulting output is saved in a csv file with related information about the model e.g. the architecture, the activation, the number of iterations, the solver, time to learn the model as so on. It appends the result, meaning when it runs multiple times, previous results are not overwritten.\n",
    "\n",
    "Iterations were changed from one run to the next from 500 to 1000 and then to 5000. \n",
    "\n",
    "While it may seem like extensive code to try different models, this is to automate the task and make it easy to try different architectures.\n",
    "\n",
    "One further update that could be helpful was to make a thrid iteration through different max iterations - that is for another day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports done and real code execution is starting at this time:  10:16:05\n",
      "Testing architecture: () with activation: relu\n",
      "Start time is:  10:16:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End time for model training is:  10:16:35\n",
      "Activation: relu, Train Accuracy: 1.00, Test Accuracy: 0.98, Time: 01:00:30 seconds\n",
      "\n",
      "Before I move on time is:  10:16:35\n",
      "Testing architecture: (5,) with activation: relu\n",
      "Start time is:  10:16:35\n",
      "End time for model training is:  10:23:35\n",
      "Activation: relu, Train Accuracy: 1.00, Test Accuracy: 0.99, Time: 01:06:59 seconds\n",
      "\n",
      "Before I move on time is:  10:23:35\n",
      "Testing architecture: (10,) with activation: relu\n",
      "Start time is:  10:23:35\n",
      "End time for model training is:  10:24:06\n",
      "Activation: relu, Train Accuracy: 1.00, Test Accuracy: 0.99, Time: 01:00:30 seconds\n",
      "\n",
      "Before I move on time is:  10:24:07\n",
      "Testing architecture: (15,) with activation: relu\n",
      "Start time is:  10:24:07\n",
      "End time for model training is:  10:25:12\n",
      "Activation: relu, Train Accuracy: 1.00, Test Accuracy: 1.00, Time: 01:01:05 seconds\n",
      "\n",
      "Before I move on time is:  10:25:13\n",
      "Testing architecture: (20,) with activation: relu\n",
      "Start time is:  10:25:13\n",
      "End time for model training is:  10:25:46\n",
      "Activation: relu, Train Accuracy: 1.00, Test Accuracy: 1.00, Time: 01:00:33 seconds\n",
      "\n",
      "Before I move on time is:  10:25:46\n",
      "Testing architecture: (5, 5) with activation: relu\n",
      "Start time is:  10:25:46\n",
      "End time for model training is:  10:26:35\n",
      "Activation: relu, Train Accuracy: 0.99, Test Accuracy: 0.99, Time: 01:00:48 seconds\n",
      "\n",
      "Before I move on time is:  10:26:35\n",
      "Testing architecture: (10, 5) with activation: relu\n",
      "Start time is:  10:26:35\n",
      "End time for model training is:  10:27:33\n",
      "Activation: relu, Train Accuracy: 1.00, Test Accuracy: 0.99, Time: 01:00:58 seconds\n",
      "\n",
      "Before I move on time is:  10:27:34\n",
      "Testing architecture: (5, 5, 5) with activation: relu\n",
      "Start time is:  10:27:34\n",
      "End time for model training is:  10:28:06\n",
      "Activation: relu, Train Accuracy: 1.00, Test Accuracy: 0.99, Time: 01:00:32 seconds\n",
      "\n",
      "Before I move on time is:  10:28:06\n",
      "Testing architecture: (10, 10, 5) with activation: relu\n",
      "Start time is:  10:28:06\n",
      "End time for model training is:  10:29:55\n",
      "Activation: relu, Train Accuracy: 1.00, Test Accuracy: 0.99, Time: 01:01:48 seconds\n",
      "\n",
      "Before I move on time is:  10:29:55\n",
      "Testing architecture: (10, 10, 10) with activation: relu\n",
      "Start time is:  10:29:55\n",
      "End time for model training is:  10:32:01\n",
      "Activation: relu, Train Accuracy: 1.00, Test Accuracy: 1.00, Time: 01:02:05 seconds\n",
      "\n",
      "Before I move on time is:  10:32:01\n",
      "Testing architecture: (15, 15, 15) with activation: relu\n",
      "Start time is:  10:32:01\n",
      "End time for model training is:  10:32:41\n",
      "Activation: relu, Train Accuracy: 1.00, Test Accuracy: 1.00, Time: 01:00:40 seconds\n",
      "\n",
      "Before I move on time is:  10:32:41\n",
      "Testing architecture: (5, 5, 5, 5) with activation: relu\n",
      "Start time is:  10:32:41\n",
      "End time for model training is:  10:34:02\n",
      "Activation: relu, Train Accuracy: 0.97, Test Accuracy: 0.97, Time: 01:01:20 seconds\n",
      "\n",
      "Before I move on time is:  10:34:02\n",
      "Testing architecture: (10, 10, 10, 10) with activation: relu\n",
      "Start time is:  10:34:02\n",
      "End time for model training is:  10:34:45\n",
      "Activation: relu, Train Accuracy: 1.00, Test Accuracy: 0.99, Time: 01:00:43 seconds\n",
      "\n",
      "Before I move on time is:  10:34:46\n",
      "Testing architecture: () with activation: tanh\n",
      "Start time is:  10:34:46\n",
      "End time for model training is:  10:35:15\n",
      "Activation: tanh, Train Accuracy: 1.00, Test Accuracy: 0.98, Time: 01:00:28 seconds\n",
      "\n",
      "Before I move on time is:  10:35:17\n",
      "Testing architecture: (5,) with activation: tanh\n",
      "Start time is:  10:35:17\n",
      "End time for model training is:  10:37:09\n",
      "Activation: tanh, Train Accuracy: 0.99, Test Accuracy: 0.99, Time: 01:01:52 seconds\n",
      "\n",
      "Before I move on time is:  10:37:09\n",
      "Testing architecture: (10,) with activation: tanh\n",
      "Start time is:  10:37:09\n",
      "End time for model training is:  10:43:21\n",
      "Activation: tanh, Train Accuracy: 1.00, Test Accuracy: 0.99, Time: 01:06:11 seconds\n",
      "\n",
      "Before I move on time is:  10:43:21\n",
      "Testing architecture: (15,) with activation: tanh\n",
      "Start time is:  10:43:21\n",
      "End time for model training is:  10:51:35\n",
      "Activation: tanh, Train Accuracy: 1.00, Test Accuracy: 0.99, Time: 01:08:13 seconds\n",
      "\n",
      "Before I move on time is:  10:51:36\n",
      "Testing architecture: (20,) with activation: tanh\n",
      "Start time is:  10:51:36\n",
      "End time for model training is:  11:07:34\n",
      "Activation: tanh, Train Accuracy: 1.00, Test Accuracy: 0.99, Time: 01:15:58 seconds\n",
      "\n",
      "Before I move on time is:  11:07:34\n",
      "Testing architecture: (5, 5) with activation: tanh\n",
      "Start time is:  11:07:34\n",
      "End time for model training is:  11:15:48\n",
      "Activation: tanh, Train Accuracy: 0.99, Test Accuracy: 0.99, Time: 01:08:14 seconds\n",
      "\n",
      "Before I move on time is:  11:15:49\n",
      "Testing architecture: (10, 5) with activation: tanh\n",
      "Start time is:  11:15:49\n",
      "End time for model training is:  11:39:24\n",
      "Activation: tanh, Train Accuracy: 1.00, Test Accuracy: 0.99, Time: 01:23:35 seconds\n",
      "\n",
      "Before I move on time is:  11:39:24\n",
      "Testing architecture: (5, 5, 5) with activation: tanh\n",
      "Start time is:  11:39:24\n",
      "End time for model training is:  11:43:20\n",
      "Activation: tanh, Train Accuracy: 0.99, Test Accuracy: 0.99, Time: 01:03:55 seconds\n",
      "\n",
      "Before I move on time is:  11:43:20\n",
      "Testing architecture: (10, 10, 5) with activation: tanh\n",
      "Start time is:  11:43:20\n",
      "End time for model training is:  12:02:25\n",
      "Activation: tanh, Train Accuracy: 1.00, Test Accuracy: 0.99, Time: 01:19:04 seconds\n",
      "\n",
      "Before I move on time is:  12:02:26\n",
      "Testing architecture: (10, 10, 10) with activation: tanh\n",
      "Start time is:  12:02:26\n",
      "End time for model training is:  12:20:45\n",
      "Activation: tanh, Train Accuracy: 1.00, Test Accuracy: 0.99, Time: 01:18:19 seconds\n",
      "\n",
      "Before I move on time is:  12:20:46\n",
      "Testing architecture: (15, 15, 15) with activation: tanh\n",
      "Start time is:  12:20:46\n",
      "End time for model training is:  12:54:33\n",
      "Activation: tanh, Train Accuracy: 1.00, Test Accuracy: 0.99, Time: 01:33:47 seconds\n",
      "\n",
      "Before I move on time is:  12:54:33\n",
      "Testing architecture: (5, 5, 5, 5) with activation: tanh\n",
      "Start time is:  12:54:33\n",
      "End time for model training is:  13:28:28\n",
      "Activation: tanh, Train Accuracy: 0.99, Test Accuracy: 0.99, Time: 01:33:54 seconds\n",
      "\n",
      "Before I move on time is:  13:28:29\n",
      "Testing architecture: (10, 10, 10, 10) with activation: tanh\n",
      "Start time is:  13:28:29\n",
      "End time for model training is:  13:53:42\n",
      "Activation: tanh, Train Accuracy: 0.99, Test Accuracy: 0.99, Time: 01:25:13 seconds\n",
      "\n",
      "Before I move on time is:  13:53:44\n",
      "Results saved to mlp_results.csv\n",
      "The results:          architecture activation solver  iterations  random_state  \\\n",
      "0                 ()       relu  lbfgs        5000            11   \n",
      "1               (5,)       relu  lbfgs        5000            11   \n",
      "2              (10,)       relu  lbfgs        5000            11   \n",
      "3              (15,)       relu  lbfgs        5000            11   \n",
      "4              (20,)       relu  lbfgs        5000            11   \n",
      "5             (5, 5)       relu  lbfgs        5000            11   \n",
      "6            (10, 5)       relu  lbfgs        5000            11   \n",
      "7          (5, 5, 5)       relu  lbfgs        5000            11   \n",
      "8        (10, 10, 5)       relu  lbfgs        5000            11   \n",
      "9       (10, 10, 10)       relu  lbfgs        5000            11   \n",
      "10      (15, 15, 15)       relu  lbfgs        5000            11   \n",
      "11      (5, 5, 5, 5)       relu  lbfgs        5000            11   \n",
      "12  (10, 10, 10, 10)       relu  lbfgs        5000            11   \n",
      "13                ()       tanh  lbfgs        5000            11   \n",
      "14              (5,)       tanh  lbfgs        5000            11   \n",
      "15             (10,)       tanh  lbfgs        5000            11   \n",
      "16             (15,)       tanh  lbfgs        5000            11   \n",
      "17             (20,)       tanh  lbfgs        5000            11   \n",
      "18            (5, 5)       tanh  lbfgs        5000            11   \n",
      "19           (10, 5)       tanh  lbfgs        5000            11   \n",
      "20         (5, 5, 5)       tanh  lbfgs        5000            11   \n",
      "21       (10, 10, 5)       tanh  lbfgs        5000            11   \n",
      "22      (10, 10, 10)       tanh  lbfgs        5000            11   \n",
      "23      (15, 15, 15)       tanh  lbfgs        5000            11   \n",
      "24      (5, 5, 5, 5)       tanh  lbfgs        5000            11   \n",
      "25  (10, 10, 10, 10)       tanh  lbfgs        5000            11   \n",
      "\n",
      "    train_accuracy  test_accuracy         time formatted_time converged  \\\n",
      "0         1.000000       0.984206    30.015726      0m 30.02s       Yes   \n",
      "1         0.998337       0.986146   419.993690      6m 59.99s       Yes   \n",
      "2         0.998522       0.992242    30.594854      0m 30.59s       Yes   \n",
      "3         1.000000       0.995290    65.780344       1m 5.78s       Yes   \n",
      "4         1.000000       0.995844    33.267188      0m 33.27s       Yes   \n",
      "5         0.991409       0.989748    48.702918      0m 48.70s       Yes   \n",
      "6         0.998707       0.992242    58.049183      0m 58.05s       Yes   \n",
      "7         0.998245       0.988085    32.383000      0m 32.38s       Yes   \n",
      "8         0.999538       0.993350   108.381780      1m 48.38s       Yes   \n",
      "9         0.999908       0.995290   125.241359       2m 5.24s       Yes   \n",
      "10        1.000000       0.995012    40.119663      0m 40.12s       Yes   \n",
      "11        0.970993       0.971737    80.263229      1m 20.26s       Yes   \n",
      "12        1.000000       0.993627    43.263988      0m 43.26s       Yes   \n",
      "13        1.000000       0.984206    28.397377      0m 28.40s       Yes   \n",
      "14        0.988453       0.985592   112.481746      1m 52.48s       Yes   \n",
      "15        0.996859       0.990856   371.742500      6m 11.74s       Yes   \n",
      "16        0.998337       0.992242   493.545087      8m 13.55s       Yes   \n",
      "17        0.999815       0.993904   958.605740     15m 58.61s       Yes   \n",
      "18        0.991501       0.986977   494.037475      8m 14.04s       Yes   \n",
      "19        0.998799       0.990302  1415.034621     23m 35.03s       Yes   \n",
      "20        0.988176       0.986423   235.682464      3m 55.68s       Yes   \n",
      "21        0.997783       0.988362  1144.834488      19m 4.83s       Yes   \n",
      "22        0.998430       0.991410  1099.532867     18m 19.53s       Yes   \n",
      "23        0.999076       0.991965  2027.364927     33m 47.36s       Yes   \n",
      "24        0.994180       0.987808  2034.869039     33m 54.87s       Yes   \n",
      "25        0.994457       0.988362  1513.646985     25m 13.65s       Yes   \n",
      "\n",
      "              timestamp  \n",
      "0   2024-12-01 10:16:35  \n",
      "1   2024-12-01 10:23:35  \n",
      "2   2024-12-01 10:24:07  \n",
      "3   2024-12-01 10:25:13  \n",
      "4   2024-12-01 10:25:46  \n",
      "5   2024-12-01 10:26:35  \n",
      "6   2024-12-01 10:27:34  \n",
      "7   2024-12-01 10:28:06  \n",
      "8   2024-12-01 10:29:55  \n",
      "9   2024-12-01 10:32:01  \n",
      "10  2024-12-01 10:32:41  \n",
      "11  2024-12-01 10:34:02  \n",
      "12  2024-12-01 10:34:46  \n",
      "13  2024-12-01 10:35:17  \n",
      "14  2024-12-01 10:37:09  \n",
      "15  2024-12-01 10:43:21  \n",
      "16  2024-12-01 10:51:36  \n",
      "17  2024-12-01 11:07:34  \n",
      "18  2024-12-01 11:15:49  \n",
      "19  2024-12-01 11:39:24  \n",
      "20  2024-12-01 11:43:20  \n",
      "21  2024-12-01 12:02:26  \n",
      "22  2024-12-01 12:20:46  \n",
      "23  2024-12-01 12:54:33  \n",
      "24  2024-12-01 13:28:29  \n",
      "25  2024-12-01 13:53:44  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "print(\"Imports done and real code execution is starting at this time: \", time.strftime(\"%H:%M:%S\", time.localtime(time.time())))\n",
    "\n",
    "# Define architectures and activation functions to test\n",
    "architectures = [\n",
    "    (),                     # No hidden layers\n",
    "    (5,),                  # 1 layer, 5 neurons\n",
    "    (10,),                 # 1 layer, 10 neurons\n",
    "    (15,),                  ## one layer 15 neurons\n",
    "    (20,),\n",
    "    (5, 5),               # 2 layers, 5 neurons each\n",
    "    (10, 5),              # 2 layers, 10 neurons in first, 5 in second\n",
    "    (5, 5, 5),\n",
    "    (10, 10, 5),         # 3 layers\n",
    "    (10, 10, 10),\n",
    "    (15, 15, 15),\n",
    "    (5, 5, 5, 5),\n",
    "    (10, 10, 10, 10),9\n",
    "]\n",
    "\n",
    "activations = ['relu', 'tanh']\n",
    "\n",
    "# Configuration parameters\n",
    "solver = 'lbfgs'           # Solver type\n",
    "max_iter = 5000             # Number of iterations\n",
    "random_state_no = 11          # Random state for reproducibility\n",
    "\n",
    "file_path = \"mlp_results.csv\"\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for activation in activations:\n",
    "    for arch in architectures:\n",
    "        print(f\"Testing architecture: {arch} with activation: {activation}\") # outputting the architecture and activation to the \"terminal\"\n",
    "        start_model_and_train = time.time() ## Starting the timer\n",
    "        print(\"Start time is: \", time.strftime(\"%H:%M:%S\", time.localtime(start_model_and_train)))\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=arch, activation=activation, solver=solver, random_state=random_state_no, max_iter=max_iter)  ## Setting up the model\n",
    "\n",
    "        # Train the model and capture warnings\n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            warnings.simplefilter(\"always\", ConvergenceWarning)\n",
    "            mlp.fit(X_train, y_train)\n",
    "            # Check for ConvergenceWarning\n",
    "            convergence_warning = any(issubclass(warn.category, ConvergenceWarning) for warn in w)\n",
    "\n",
    "        #mlp.fit(X_train, y_train)\n",
    "\n",
    "        end_model_and_train = time.time() ## End timer logging time for training\n",
    "        print(\"End time for model training is: \", time.strftime(\"%H:%M:%S\", time.localtime(time.time())))\n",
    "        \n",
    "        ## Evaluate the model\n",
    "        train_acc = mlp.score(X_train, y_train)\n",
    "        test_acc = mlp.score(X_test, y_test)\n",
    "        elapsed_time = end_model_and_train - start_model_and_train\n",
    "\n",
    "        ## A bit of formatting, so time is in hh:mm:ss and not just number of seconds\n",
    "        minutes, seconds = divmod(elapsed_time, 60)\n",
    "        formatted_time = f\"{int(minutes)}m {seconds:.2f}s\"\n",
    "\n",
    "       \n",
    "        ## Save results\n",
    "        results.append({\n",
    "            \"architecture\": arch,\n",
    "            \"activation\": activation,\n",
    "            \"solver\": solver,\n",
    "            \"iterations\": max_iter,\n",
    "            \"random_state\": random_state_no,\n",
    "            \"train_accuracy\": train_acc,\n",
    "            \"test_accuracy\": test_acc,\n",
    "            \"time\": elapsed_time,\n",
    "            \"formatted_time\": formatted_time,\n",
    "            \"converged\": \"No (Did not converge)\" if convergence_warning else \"Yes\",\n",
    "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        })\n",
    "        print(f\"Activation: {activation}, Train Accuracy: {train_acc:.2f}, Test Accuracy: {test_acc:.2f}, Time: {time.strftime(\"%H:%M:%S\", time.localtime(elapsed_time))} seconds\\n\")\n",
    "        print(\"Before I move on time is: \", time.strftime(\"%H:%M:%S\", time.localtime(time.time())))\n",
    "\n",
    "# Create a DataFrame to save results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Append results to CSV\n",
    "if os.path.exists(file_path):\n",
    "    # Load existing data and append new results\n",
    "    existing_data = pd.read_csv(file_path)\n",
    "    updated_data = pd.concat([existing_data, results_df], ignore_index=True)\n",
    "    updated_data.to_csv(file_path, index=False)\n",
    "else:\n",
    "    # Create a new CSV file\n",
    "    results_df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"Results saved to\", file_path)\n",
    "\n",
    "print(\"The results: \",results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provided results saved to mlp_results_updated.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Provided results data\n",
    "provided_results = [\n",
    "    {\"architecture\": \"()\", \"activation\": \"relu\", \"train_accuracy\": 1.000000, \"test_accuracy\": 0.984206, \"time\": 97.39, \"convergence_warning\": False},\n",
    "    {\"architecture\": \"(5,)\", \"activation\": \"relu\", \"train_accuracy\": 0.990947, \"test_accuracy\": 0.989194, \"time\": 327.91, \"convergence_warning\": True},\n",
    "    {\"architecture\": \"(10,)\", \"activation\": \"relu\", \"train_accuracy\": 0.998522, \"test_accuracy\": 0.992242, \"time\": 87.67, \"convergence_warning\": False},\n",
    "    {\"architecture\": \"(5, 5)\", \"activation\": \"relu\", \"train_accuracy\": 0.991409, \"test_accuracy\": 0.989748, \"time\": 210.90, \"convergence_warning\": False},\n",
    "    {\"architecture\": \"(10, 5)\", \"activation\": \"relu\", \"train_accuracy\": 0.998707, \"test_accuracy\": 0.992242, \"time\": 214.71, \"convergence_warning\": False},\n",
    "    {\"architecture\": \"(10, 10, 5)\", \"activation\": \"relu\", \"train_accuracy\": 0.999538, \"test_accuracy\": 0.993350, \"time\": 339.80, \"convergence_warning\": False},\n",
    "    {\"architecture\": \"()\", \"activation\": \"tanh\", \"train_accuracy\": 1.000000, \"test_accuracy\": 0.984206, \"time\": 110.59, \"convergence_warning\": False},\n",
    "    {\"architecture\": \"(5,)\", \"activation\": \"tanh\", \"train_accuracy\": 0.988453, \"test_accuracy\": 0.985592, \"time\": 412.76, \"convergence_warning\": True},\n",
    "    {\"architecture\": \"(10,)\", \"activation\": \"tanh\", \"train_accuracy\": 0.993626, \"test_accuracy\": 0.987254, \"time\": 489.80, \"convergence_warning\": True},\n",
    "    {\"architecture\": \"(5, 5)\", \"activation\": \"tanh\", \"train_accuracy\": 0.987898, \"test_accuracy\": 0.987254, \"time\": 707.54, \"convergence_warning\": True},\n",
    "    {\"architecture\": \"(10, 5)\", \"activation\": \"tanh\", \"train_accuracy\": 0.992702, \"test_accuracy\": 0.990025, \"time\": 655.37, \"convergence_warning\": True},\n",
    "    {\"architecture\": \"(10, 10, 5)\", \"activation\": \"tanh\", \"train_accuracy\": 0.992517, \"test_accuracy\": 0.988640, \"time\": 940.86, \"convergence_warning\": True},\n",
    "]\n",
    "\n",
    "# File path for the results\n",
    "file_path = \"mlp_results_updated.csv\"\n",
    "\n",
    "# Enhance results with additional information\n",
    "for result in provided_results:\n",
    "    # Add timestamp\n",
    "    result[\"timestamp\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Determine convergence status\n",
    "    result[\"converged\"] = \"No (Did not converge)\" if result[\"convergence_warning\"] else \"Yes\"\n",
    "    \n",
    "    # Convert time to minutes and seconds\n",
    "    minutes, seconds = divmod(result[\"time\"], 60)\n",
    "    result[\"formatted_time\"] = f\"{int(minutes)}m {seconds:.2f}s\"\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "results_df = pd.DataFrame(provided_results)\n",
    "\n",
    "# Save or append the results to a CSV file\n",
    "if os.path.exists(file_path):\n",
    "    # Append new data to the existing file\n",
    "    existing_data = pd.read_csv(file_path)\n",
    "    updated_data = pd.concat([existing_data, results_df], ignore_index=True)\n",
    "    updated_data.to_csv(file_path, index=False)\n",
    "else:\n",
    "    # Create a new file if it doesn't exist\n",
    "    results_df.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"Provided results saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of misclassified samples: [  36   72  110  271  276  304  392  454  641  716 1029 1055 1097 1117\n",
      " 1637 1686 1694 1723 1729 1930 2243 2298 2305 2393 2428 2482 2551 2609\n",
      " 2677 2883 2933 2981 3084 3250 3271 3309 3492 3514 3536]\n"
     ]
    }
   ],
   "source": [
    "## Exercise: Using the numpy where() function, one can extract the indices of the test cases that were misclassified: <br> `misclass = np.where(test != predictions)` <br>\n",
    "\n",
    "## This piece of code makes a prediction based on the model define in the last section. Basically mlp is the last model defined (4 layered NN model with 10 nodes in each, using activation tanh) and used in the previous section\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Generate predictions\n",
    "predictions = mlp.predict(X_test)\n",
    "\n",
    "# Find misclassified indices\n",
    "misclass_indices = np.where(y_test != predictions)[0]\n",
    "\n",
    "print(\"Indices of misclassified samples:\", misclass_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list generated above is an array of the cases where the prediction differed from the actual result. Each number represent and index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Exercise: Inspect some misclassified cases. Do they correspond to hard to recognize digits (also for the human reader)? \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## This code iterates over a number of cases where the prediction did not match the result and visualizes the cases ini order for the (human) reader can get an impression of if they were indeed difficult cases to discern\n",
    "\n",
    "# Iterate over the first 10 misclassified samples\n",
    "for idx in misclass_indices[:10]:  # Limit visualization to the first 10\n",
    "    # Reshape and display the image\n",
    "    plt.imshow(X_test[idx].reshape(28, 28), cmap='gray')\n",
    "    \n",
    "    # Use .iloc to access the true label by positional index\n",
    "    true_label = y_test.iloc[idx] if isinstance(y_test, pd.Series) else y_test[idx]\n",
    "    predicted_label = predictions[idx]\n",
    "    \n",
    "    plt.title(f\"True: {true_label}, Predicted: {predicted_label}\")\n",
    "    plt.axis('off')  # Turn off axis labels for clarity\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first datapoint now is: \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3' '3' '3' ... '3' '7' '3']\n",
      "Time it took to learn the linear kernel model: 3.32 seconds\n",
      "Training Accuracy: 1.00\n",
      "Test Accuracy: 0.98\n",
      "Testing architecture: () with activation: relu\n",
      "Start time is:  10:50:09\n",
      "End time for model training is:  10:50:11\n",
      "Before I move on time is:  10:50:11\n",
      "Testing architecture: (5,) with activation: relu\n",
      "Start time is:  10:50:11\n",
      "End time for model training is:  10:50:27\n",
      "Before I move on time is:  10:50:27\n",
      "Testing architecture: (10,) with activation: relu\n",
      "Start time is:  10:50:27\n",
      "End time for model training is:  10:50:31\n",
      "Before I move on time is:  10:50:31\n",
      "Testing architecture: (15,) with activation: relu\n",
      "Start time is:  10:50:31\n",
      "End time for model training is:  10:50:36\n",
      "Before I move on time is:  10:50:36\n",
      "Testing architecture: (20,) with activation: relu\n",
      "Start time is:  10:50:36\n",
      "End time for model training is:  10:50:39\n",
      "Before I move on time is:  10:50:39\n",
      "Testing architecture: (5, 5) with activation: relu\n",
      "Start time is:  10:50:39\n",
      "End time for model training is:  10:50:41\n",
      "Before I move on time is:  10:50:41\n",
      "Testing architecture: (10, 5) with activation: relu\n",
      "Start time is:  10:50:41\n",
      "End time for model training is:  10:50:48\n",
      "Before I move on time is:  10:50:48\n",
      "Testing architecture: (5, 5, 5) with activation: relu\n",
      "Start time is:  10:50:48\n",
      "End time for model training is:  10:50:51\n",
      "Before I move on time is:  10:50:51\n",
      "Testing architecture: (10, 10, 5) with activation: relu\n",
      "Start time is:  10:50:51\n",
      "End time for model training is:  10:50:55\n",
      "Before I move on time is:  10:50:56\n",
      "Testing architecture: (10, 10, 10) with activation: relu\n",
      "Start time is:  10:50:56\n",
      "End time for model training is:  10:51:11\n",
      "Before I move on time is:  10:51:11\n",
      "Testing architecture: (15, 15, 15) with activation: relu\n",
      "Start time is:  10:51:11\n",
      "End time for model training is:  10:51:16\n",
      "Before I move on time is:  10:51:16\n",
      "Testing architecture: (5, 5, 5, 5) with activation: relu\n",
      "Start time is:  10:51:16\n",
      "End time for model training is:  10:51:37\n",
      "Before I move on time is:  10:51:37\n",
      "Testing architecture: (10, 10, 10, 10) with activation: relu\n",
      "Start time is:  10:51:37\n",
      "End time for model training is:  10:51:42\n",
      "Before I move on time is:  10:51:42\n",
      "Testing architecture: () with activation: tanh\n",
      "Start time is:  10:51:42\n",
      "End time for model training is:  10:51:45\n",
      "Before I move on time is:  10:51:45\n",
      "Testing architecture: (5,) with activation: tanh\n",
      "Start time is:  10:51:45\n",
      "End time for model training is:  10:52:07\n",
      "Before I move on time is:  10:52:07\n",
      "Testing architecture: (10,) with activation: tanh\n",
      "Start time is:  10:52:07\n",
      "End time for model training is:  10:53:11\n",
      "Before I move on time is:  10:53:11\n",
      "Testing architecture: (15,) with activation: tanh\n",
      "Start time is:  10:53:11\n",
      "End time for model training is:  10:54:20\n",
      "Before I move on time is:  10:54:20\n",
      "Testing architecture: (20,) with activation: tanh\n",
      "Start time is:  10:54:20\n",
      "End time for model training is:  10:55:21\n",
      "Before I move on time is:  10:55:22\n",
      "Testing architecture: (5, 5) with activation: tanh\n",
      "Start time is:  10:55:22\n",
      "End time for model training is:  10:56:00\n",
      "Before I move on time is:  10:56:00\n",
      "Testing architecture: (10, 5) with activation: tanh\n",
      "Start time is:  10:56:00\n",
      "End time for model training is:  10:58:36\n",
      "Before I move on time is:  10:58:36\n",
      "Testing architecture: (5, 5, 5) with activation: tanh\n",
      "Start time is:  10:58:36\n",
      "End time for model training is:  10:59:14\n",
      "Before I move on time is:  10:59:14\n",
      "Testing architecture: (10, 10, 5) with activation: tanh\n",
      "Start time is:  10:59:14\n",
      "End time for model training is:  11:01:37\n",
      "Before I move on time is:  11:01:37\n",
      "Testing architecture: (10, 10, 10) with activation: tanh\n",
      "Start time is:  11:01:37\n",
      "End time for model training is:  11:04:33\n",
      "Before I move on time is:  11:04:33\n",
      "Testing architecture: (15, 15, 15) with activation: tanh\n",
      "Start time is:  11:04:33\n",
      "End time for model training is:  11:06:52\n",
      "Before I move on time is:  11:06:52\n",
      "Testing architecture: (5, 5, 5, 5) with activation: tanh\n",
      "Start time is:  11:06:52\n",
      "End time for model training is:  11:07:45\n",
      "Before I move on time is:  11:07:45\n",
      "Testing architecture: (10, 10, 10, 10) with activation: tanh\n",
      "Start time is:  11:07:45\n",
      "End time for model training is:  11:10:35\n",
      "Before I move on time is:  11:10:36\n",
      "Results saved to mlp_results.csv\n",
      "The results:          architecture activation solver  iterations  random_state  \\\n",
      "0                 ()       relu  lbfgs        5000            11   \n",
      "1               (5,)       relu  lbfgs        5000            11   \n",
      "2              (10,)       relu  lbfgs        5000            11   \n",
      "3              (15,)       relu  lbfgs        5000            11   \n",
      "4              (20,)       relu  lbfgs        5000            11   \n",
      "5             (5, 5)       relu  lbfgs        5000            11   \n",
      "6            (10, 5)       relu  lbfgs        5000            11   \n",
      "7          (5, 5, 5)       relu  lbfgs        5000            11   \n",
      "8        (10, 10, 5)       relu  lbfgs        5000            11   \n",
      "9       (10, 10, 10)       relu  lbfgs        5000            11   \n",
      "10      (15, 15, 15)       relu  lbfgs        5000            11   \n",
      "11      (5, 5, 5, 5)       relu  lbfgs        5000            11   \n",
      "12  (10, 10, 10, 10)       relu  lbfgs        5000            11   \n",
      "13                ()       tanh  lbfgs        5000            11   \n",
      "14              (5,)       tanh  lbfgs        5000            11   \n",
      "15             (10,)       tanh  lbfgs        5000            11   \n",
      "16             (15,)       tanh  lbfgs        5000            11   \n",
      "17             (20,)       tanh  lbfgs        5000            11   \n",
      "18            (5, 5)       tanh  lbfgs        5000            11   \n",
      "19           (10, 5)       tanh  lbfgs        5000            11   \n",
      "20         (5, 5, 5)       tanh  lbfgs        5000            11   \n",
      "21       (10, 10, 5)       tanh  lbfgs        5000            11   \n",
      "22      (10, 10, 10)       tanh  lbfgs        5000            11   \n",
      "23      (15, 15, 15)       tanh  lbfgs        5000            11   \n",
      "24      (5, 5, 5, 5)       tanh  lbfgs        5000            11   \n",
      "25  (10, 10, 10, 10)       tanh  lbfgs        5000            11   \n",
      "\n",
      "    train_accuracy  test_accuracy        time formatted_time converged  \\\n",
      "0         1.000000       0.984206    2.663032       0m 2.66s       Yes   \n",
      "1         0.991686       0.990856   15.541131      0m 15.54s       Yes   \n",
      "2         0.999815       0.993350    3.808351       0m 3.81s       Yes   \n",
      "3         1.000000       0.995012    5.368036       0m 5.37s       Yes   \n",
      "4         1.000000       0.995844    2.629629       0m 2.63s       Yes   \n",
      "5         0.987529       0.989194    2.020052       0m 2.02s       Yes   \n",
      "6         0.999076       0.991133    6.545460       0m 6.55s       Yes   \n",
      "7         0.998337       0.989471    2.742559       0m 2.74s       Yes   \n",
      "8         0.999630       0.993627    4.741474       0m 4.74s       Yes   \n",
      "9         0.999815       0.996398   15.350420      0m 15.35s       Yes   \n",
      "10        1.000000       0.995290    5.258553       0m 5.26s       Yes   \n",
      "11        0.978753       0.980327   20.673042      0m 20.67s       Yes   \n",
      "12        1.000000       0.993627    4.926589       0m 4.93s       Yes   \n",
      "13        1.000000       0.984206    2.809197       0m 2.81s       Yes   \n",
      "14        0.989654       0.988640   21.971160      0m 21.97s       Yes   \n",
      "15        0.997875       0.992796   63.832153       1m 3.83s       Yes   \n",
      "16        0.995843       0.991965   68.736707       1m 8.74s       Yes   \n",
      "17        0.999630       0.992242   61.600496       1m 1.60s       Yes   \n",
      "18        0.990115       0.986700   38.629715      0m 38.63s       Yes   \n",
      "19        0.999261       0.990856  155.802536      2m 35.80s       Yes   \n",
      "20        0.989931       0.987531   37.823917      0m 37.82s       Yes   \n",
      "21        0.998430       0.987531  142.965929      2m 22.97s       Yes   \n",
      "22        0.998614       0.991133  176.060876      2m 56.06s       Yes   \n",
      "23        0.998430       0.991965  138.215482      2m 18.22s       Yes   \n",
      "24        0.989746       0.985869   53.542015      0m 53.54s       Yes   \n",
      "25        0.997875       0.987531  169.872821      2m 49.87s       Yes   \n",
      "\n",
      "              timestamp  \n",
      "0   2024-12-06 10:50:11  \n",
      "1   2024-12-06 10:50:27  \n",
      "2   2024-12-06 10:50:31  \n",
      "3   2024-12-06 10:50:36  \n",
      "4   2024-12-06 10:50:39  \n",
      "5   2024-12-06 10:50:41  \n",
      "6   2024-12-06 10:50:48  \n",
      "7   2024-12-06 10:50:51  \n",
      "8   2024-12-06 10:50:56  \n",
      "9   2024-12-06 10:51:11  \n",
      "10  2024-12-06 10:51:16  \n",
      "11  2024-12-06 10:51:37  \n",
      "12  2024-12-06 10:51:42  \n",
      "13  2024-12-06 10:51:45  \n",
      "14  2024-12-06 10:52:07  \n",
      "15  2024-12-06 10:53:11  \n",
      "16  2024-12-06 10:54:20  \n",
      "17  2024-12-06 10:55:22  \n",
      "18  2024-12-06 10:56:00  \n",
      "19  2024-12-06 10:58:36  \n",
      "20  2024-12-06 10:59:14  \n",
      "21  2024-12-06 11:01:37  \n",
      "22  2024-12-06 11:04:33  \n",
      "23  2024-12-06 11:06:52  \n",
      "24  2024-12-06 11:07:45  \n",
      "25  2024-12-06 11:10:36  \n"
     ]
    }
   ],
   "source": [
    "## Question: How do results (time and accuracy) change, depending on whether you consider an 'easy' binary task \n",
    "# (e.g., distinguishing '1' and '0'), or a more difficult one (e.g., '4' vs. '5'). \n",
    "\n",
    "digit0='3'\n",
    "digit1='7'\n",
    "mnist_bin_data=mnist.data[np.logical_or(mnist.target==digit0,mnist.target==digit1)]\n",
    "mnist_bin_target=mnist.target[np.logical_or(mnist.target==digit0,mnist.target==digit1)]\n",
    "print(\"The first datapoint now is: \\n\")\n",
    "plt.imshow(mnist_bin_data[0].reshape(28,28),cmap=plt.cm.gray_r)\n",
    "plt.show()\n",
    "print(mnist_bin_target)\n",
    "\n",
    "## Split the mnist_bin data into training and test set. \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist_bin_data, mnist_bin_target, random_state=1) # test size 25% and training 75%\n",
    "\n",
    "kernel_type = 'linear'\n",
    "start=time.time()\n",
    "linear_svm = SVC(kernel=kernel_type).fit(X_train,y_train)\n",
    "end=time.time()\n",
    "elapsed_time=end-start \n",
    "print(f\"Time it took to learn the {kernel_type} kernel model: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Calculate accuracy on training data\n",
    "train_accuracy = linear_svm.score(X_train, y_train)\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "test_accuracy = linear_svm.score(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "#print(\"Imports done and real code execution is starting at this time: \", time.strftime(\"%H:%M:%S\", time.localtime(time.time())))\n",
    "\n",
    "# Define architectures and activation functions to test\n",
    "architectures = [\n",
    "    (),                     # No hidden layers\n",
    "    (5,),                  # 1 layer, 5 neurons\n",
    "    (10,),                 # 1 layer, 10 neurons\n",
    "    (15,),                  ## one layer 15 neurons\n",
    "    (20,),\n",
    "    (5, 5),               # 2 layers, 5 neurons each\n",
    "    (10, 5),              # 2 layers, 10 neurons in first, 5 in second\n",
    "    (5, 5, 5),\n",
    "    (10, 10, 5),         # 3 layers\n",
    "    (10, 10, 10),\n",
    "    (15, 15, 15),\n",
    "    (5, 5, 5, 5),\n",
    "    (10, 10, 10, 10),\n",
    "]\n",
    "\n",
    "activations = ['relu', 'tanh']\n",
    "\n",
    "# Configuration parameters\n",
    "solver = 'lbfgs'           # Solver type\n",
    "max_iter = 5000             # Number of iterations\n",
    "random_state_no = 11          # Random state for reproducibility\n",
    "\n",
    "file_path = \"mlp_results.csv\"\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for activation in activations:\n",
    "    for arch in architectures:\n",
    "        print(f\"Testing architecture: {arch} with activation: {activation}\")\n",
    "        start_model_and_train = time.time()\n",
    "        print(\"Start time is: \", time.strftime(\"%H:%M:%S\", time.localtime(start_model_and_train)))\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=arch, activation=activation, solver=solver, random_state=random_state_no, max_iter=max_iter)            # Number of iterations\n",
    "\n",
    "        # Train the model and capture warnings\n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            warnings.simplefilter(\"always\", ConvergenceWarning)\n",
    "            mlp.fit(X_train, y_train)\n",
    "            # Check for ConvergenceWarning\n",
    "            convergence_warning = any(issubclass(warn.category, ConvergenceWarning) for warn in w)\n",
    "\n",
    "        #mlp.fit(X_train, y_train)\n",
    "\n",
    "        end_model_and_train = time.time()\n",
    "        print(\"End time for model training is: \", time.strftime(\"%H:%M:%S\", time.localtime(time.time())))\n",
    "        \n",
    "        # Evaluate\n",
    "        train_acc = mlp.score(X_train, y_train)\n",
    "        test_acc = mlp.score(X_test, y_test)\n",
    "        elapsed_time = end_model_and_train - start_model_and_train\n",
    "\n",
    "        minutes, seconds = divmod(elapsed_time, 60)\n",
    "        formatted_time = f\"{int(minutes)}m {seconds:.2f}s\"\n",
    "\n",
    "       \n",
    "        # Save results\n",
    "        results.append({\n",
    "            \"architecture\": arch,\n",
    "            \"activation\": activation,\n",
    "            \"solver\": solver,\n",
    "            \"iterations\": max_iter,\n",
    "            \"random_state\": random_state_no,\n",
    "            \"train_accuracy\": train_acc,\n",
    "            \"test_accuracy\": test_acc,\n",
    "            \"time\": elapsed_time,\n",
    "            \"formatted_time\": formatted_time,\n",
    "            \"converged\": \"No (Did not converge)\" if convergence_warning else \"Yes\",\n",
    "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        })\n",
    "        #print(f\"Activation: {activation}, Train Accuracy: {train_acc:.2f}, Test Accuracy: {test_acc:.2f}, Time: {time.strftime(\"%H:%M:%S\", time.localtime(elapsed_time))} seconds\\n\")\n",
    "        print(\"Before I move on time is: \", time.strftime(\"%H:%M:%S\", time.localtime(time.time())))\n",
    "\n",
    "# Create a DataFrame to save results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Append results to CSV\n",
    "if os.path.exists(file_path):\n",
    "    # Load existing data and append new results\n",
    "    existing_data = pd.read_csv(file_path)\n",
    "    updated_data = pd.concat([existing_data, results_df], ignore_index=True)\n",
    "    updated_data.to_csv(file_path, index=False)\n",
    "else:\n",
    "    # Create a new CSV file\n",
    "    results_df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"Results saved to\", file_path)\n",
    "\n",
    "print(\"The results: \",results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pair: 7 and 3\n",
      "Training SVC for pair 7-3\n",
      "Training NN for pair 7-3 with architecture (), solver lbfgs, iterations 5000\n",
      "Training NN for pair 7-3 with architecture (10,), solver lbfgs, iterations 5000\n",
      "Training NN for pair 7-3 with architecture 20, solver lbfgs, iterations 5000\n",
      "Training NN for pair 7-3 with architecture (15, 15, 15), solver lbfgs, iterations 5000\n",
      "Processing pair: 4 and 5\n",
      "Training SVC for pair 4-5\n",
      "Training NN for pair 4-5 with architecture (), solver lbfgs, iterations 5000\n",
      "Training NN for pair 4-5 with architecture (10,), solver lbfgs, iterations 5000\n",
      "Training NN for pair 4-5 with architecture 20, solver lbfgs, iterations 5000\n",
      "Training NN for pair 4-5 with architecture (15, 15, 15), solver lbfgs, iterations 5000\n",
      "Processing pair: 0 and 1\n",
      "Training SVC for pair 0-1\n",
      "Training NN for pair 0-1 with architecture (), solver lbfgs, iterations 5000\n",
      "Training NN for pair 0-1 with architecture (10,), solver lbfgs, iterations 5000\n",
      "Training NN for pair 0-1 with architecture 20, solver lbfgs, iterations 5000\n",
      "Training NN for pair 0-1 with architecture (15, 15, 15), solver lbfgs, iterations 5000\n",
      "Results saved to pair_runs.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "## Question: How do results (time and accuracy) change, depending on whether you consider an 'easy' binary task \n",
    "# (e.g., distinguishing '1' and '0'), or a more difficult one (e.g., '4' vs. '5'). \n",
    "\n",
    "## This next code does a couple of things, let's run through the idea\n",
    "## In the previous section a number of models were identified that had a good performance, in that accurancy on the test set was very good and the time to learn the model was also better than its peers. These \n",
    "#  were based on comparing 3 and 7\n",
    "## The purpose of this section is to try a number of pairs to see if performance for the models that performed well on 3 and 7 is also good on these pairs. \n",
    "\n",
    "## Specifically the pairs 3 and 7, 4 and 5, as well as 0 and 1 are tried. The architecture is configured in the beginning, using the same resolver and with a preset number of max iterations. During the experiment I did change\n",
    "#  the number of iterations.\n",
    "## The results along the configuration is saved in a csv file.\n",
    "\n",
    "# Define digit pairs, neural network configurations, and result storage\n",
    "digit_pairs = [(7, 3), (4, 5), (0, 1)]  ## The pairs that are tried\n",
    "## Setting up the configuration for the architecture\n",
    "nn_configurations = [\n",
    "    {\"architecture\": (), \"solver\": \"lbfgs\", \"iterations\": 5000},\n",
    "    {\"architecture\": (10,), \"solver\": \"lbfgs\", \"iterations\": 5000},\n",
    "    {\"architecture\": (20), \"solver\": \"lbfgs\", \"iterations\": 5000},\n",
    "    {\"architecture\": (15,15,15), \"solver\": \"lbfgs\", \"iterations\": 5000},\n",
    "]\n",
    "## Array to save the results\n",
    "results = []\n",
    "\n",
    "## Name of file to be saved\n",
    "file_path = \"pair_runs.csv\"\n",
    "\n",
    "# Loop through each pair of digits\n",
    "for digit1, digit2 in digit_pairs:\n",
    "    print(f\"Processing pair: {digit1} and {digit2}\")\n",
    "\n",
    "    # Filter dataset for the current pair\n",
    "    indices = np.logical_or(mnist.target == str(digit1), mnist.target == str(digit2))\n",
    "    X_pair = mnist.data[indices]\n",
    "    y_pair = mnist.target[indices]\n",
    "    y_pair = np.where(y_pair == str(digit1), digit1, digit2)\n",
    "\n",
    "    ## Splitting the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pair, y_pair, random_state=11)\n",
    "\n",
    "    # Train SVC model\n",
    "    print(f\"Training SVC for pair {digit1}-{digit2}\")\n",
    "    start_svc = time.time()\n",
    "    svc = SVC(kernel=\"linear\", random_state=11)\n",
    "    svc.fit(X_train, y_train)\n",
    "    end_svc = time.time()\n",
    "\n",
    "    # Evaluate SVC model\n",
    "    svc_train_acc = svc.score(X_train, y_train)\n",
    "    svc_test_acc = svc.score(X_test, y_test)\n",
    "    svc_time = end_svc - start_svc\n",
    "\n",
    "    # Save SVC model\n",
    "    svc_model_name = f\"svc_{digit1}{digit2}\"\n",
    "    #models[svc_model_name] = svc\n",
    "\n",
    "    # Save SVC results\n",
    "    results.append({\n",
    "        \"pair\": f\"{digit1}-{digit2}\",\n",
    "        \"model\": svc_model_name,\n",
    "        \"train_accuracy\": svc_train_acc,\n",
    "        \"test_accuracy\": svc_test_acc,\n",
    "        \"time\": svc_time,\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    })\n",
    "\n",
    "    # Train NN models for the current pair\n",
    "    for config in nn_configurations:\n",
    "        arch = config[\"architecture\"]\n",
    "        solver = config[\"solver\"]\n",
    "        iterations = config[\"iterations\"]\n",
    "\n",
    "        print(f\"Training NN for pair {digit1}-{digit2} with architecture {arch}, solver {solver}, iterations {iterations}\")\n",
    "        start_nn = time.time()\n",
    "        nn = MLPClassifier(hidden_layer_sizes=arch, solver=solver, max_iter=iterations, random_state=11)\n",
    "        \n",
    "        ## Try catch to cater for convergence warning\n",
    "        try:\n",
    "            nn.fit(X_train, y_train)\n",
    "            converged = \"Yes\"\n",
    "        except Exception as e:\n",
    "            converged = \"No\"\n",
    "\n",
    "        end_nn = time.time()\n",
    "\n",
    "        # Evaluate NN model\n",
    "        nn_train_acc = nn.score(X_train, y_train) if converged == \"Yes\" else \"N/A\"\n",
    "        nn_test_acc = nn.score(X_test, y_test) if converged == \"Yes\" else \"N/A\"\n",
    "        nn_time = end_nn - start_nn\n",
    "\n",
    "        # Save NN model\n",
    "        #nn_model_name = f\"nn_{digit1}{digit2}_{'-'.join(map(str, arch)) if arch else 'none'}\"\n",
    "        #models[nn_model_name] = nn\n",
    "\n",
    "        # Save NN results\n",
    "        results.append({\n",
    "            \"pair\": f\"{digit1}-{digit2}\",\n",
    "            #\"model\": nn_model_name,\n",
    "            \"architecture\": arch,\n",
    "            \"solver\": solver,\n",
    "            \"iterations\": iterations,\n",
    "            \"train_accuracy\": nn_train_acc,\n",
    "            \"test_accuracy\": nn_test_acc,\n",
    "            \"time\": nn_time,\n",
    "            \"converged\": converged,\n",
    "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        })\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "## If the file already exists then append data or else create the file\n",
    "if os.path.exists(file_path):\n",
    "    # Append new data to the existing file\n",
    "    existing_data = pd.read_csv(file_path)\n",
    "    updated_data = pd.concat([existing_data, results_df], ignore_index=True)\n",
    "    updated_data.to_csv(file_path, index=False)\n",
    "else:\n",
    "    # Create a new CSV file\n",
    "    results_df.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"Results saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVC on full dataset\n"
     ]
    }
   ],
   "source": [
    "## Exercise: Identify one or several good configurations that give a reasonable combination of accuracy and runtime. Use these configurations to perform a full \n",
    "# classification of the 10 classes in the original dataset (after split into train/test).\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = fetch_openml(name=\"mnist_784\", version=1, as_frame=False)\n",
    "X = mnist.data\n",
    "y = mnist.target.astype(int)  # Ensure labels are integers\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)\n",
    "\n",
    "# Results storage\n",
    "results = []\n",
    "\n",
    "# File path for saving results\n",
    "file_path = \"full_dataset_runs.csv\"\n",
    "\n",
    "def format_time(seconds):\n",
    "    # Convert time in seconds to hh:mm:ss format.\n",
    "    hours, remainder = divmod(seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return f\"{int(hours):02}:{int(minutes):02}:{seconds:05.2f}\"\n",
    "\n",
    "### Train SVC on full dataset ###\n",
    "print(\"Training SVC on full dataset\")\n",
    "start_svc = time.time()\n",
    "svc = SVC(kernel=\"linear\", random_state=11)\n",
    "svc.fit(X_train, y_train)\n",
    "end_svc = time.time()\n",
    "\n",
    "# Evaluate SVC\n",
    "svc_train_acc = svc.score(X_train, y_train)\n",
    "svc_test_acc = svc.score(X_test, y_test)\n",
    "svc_time = end_svc - start_svc\n",
    "\n",
    "# Save SVC results\n",
    "results.append({\n",
    "    \"model\": \"svc_full\",\n",
    "    \"train_accuracy\": svc_train_acc,\n",
    "    \"test_accuracy\": svc_test_acc,\n",
    "    \"time\": format_time(svc_time),\n",
    "    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "})\n",
    "\n",
    "### Train NN on full dataset ###\n",
    "print(\"Training NN on full dataset with 1 layer (20 nodes)\")\n",
    "start_nn = time.time()\n",
    "nn = MLPClassifier(hidden_layer_sizes=(20,), solver=\"lbfgs\", max_iter=500, random_state=11)\n",
    "\n",
    "try:\n",
    "    nn.fit(X_train, y_train)\n",
    "    converged = \"Yes\"\n",
    "except Exception as e:\n",
    "    converged = \"No\"\n",
    "end_nn = time.time()\n",
    "\n",
    "# Evaluate NN\n",
    "nn_train_acc = nn.score(X_train, y_train) if converged == \"Yes\" else \"N/A\"\n",
    "nn_test_acc = nn.score(X_test, y_test) if converged == \"Yes\" else \"N/A\"\n",
    "nn_time = end_nn - start_nn\n",
    "\n",
    "# Save NN results\n",
    "results.append({\n",
    "    \"model\": \"nn_full_20\",\n",
    "    \"architecture\": (20,),\n",
    "    \"solver\": \"lbfgs\",\n",
    "    \"iterations\": 500,\n",
    "    \"train_accuracy\": nn_train_acc,\n",
    "    \"test_accuracy\": nn_test_acc,\n",
    "    \"time\": format_time(nn_time),\n",
    "    \"converged\": converged,\n",
    "    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "})\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    # Append new data to the existing file\n",
    "    existing_data = pd.read_csv(file_path)\n",
    "    updated_data = pd.concat([existing_data, results_df], ignore_index=True)\n",
    "    updated_data.to_csv(file_path, index=False)\n",
    "else:\n",
    "    # Create a new CSV file\n",
    "    results_df.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"Results saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below loads the data and makes a train and a test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data fetched\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "    \n",
    "mnist = fetch_openml(name=\"mnist_784\", version=1, as_frame=False)\n",
    "print(\"data fetched\")\n",
    "X = mnist.data\n",
    "y = mnist.target.astype(int)  # Ensure labels are integers\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code iterates through a number of architectures with the full data set and a set of max iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started at 2024-12-06 09:40:06 with layers=(), solver=lbfgs, max_iter=500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KennethElong(KEEL)\\IdeaProjects\\firstPythonProject\\firstPyhtonProject\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed at 2024-12-06 09:41:13\n",
      "Evaluation started at 2024-12-06 09:41:13\n",
      "Evaluation completed at 2024-12-06 09:41:13\n",
      "Iteration Result: {'layers': (), 'solver': 'lbfgs', 'max_iter': 500, 'train_accuracy (%)': '92.9107', 'test_accuracy (%)': '89.8786', 'training_time': '00:01:07', 'evaluation_time': '00:00:00', 'converged': 'No (Reached max_iter)', 'start_time': '2024-12-06 09:40:06', 'end_time': '2024-12-06 09:41:13'}\n",
      "Training started at 2024-12-06 09:41:13 with layers=(), solver=lbfgs, max_iter=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KennethElong(KEEL)\\IdeaProjects\\firstPythonProject\\firstPyhtonProject\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed at 2024-12-06 09:45:37\n",
      "Evaluation started at 2024-12-06 09:45:37\n",
      "Evaluation completed at 2024-12-06 09:45:37\n",
      "Iteration Result: {'layers': (), 'solver': 'lbfgs', 'max_iter': 2000, 'train_accuracy (%)': '94.3268', 'test_accuracy (%)': '91.4071', 'training_time': '00:04:23', 'evaluation_time': '00:00:00', 'converged': 'No (Reached max_iter)', 'start_time': '2024-12-06 09:41:13', 'end_time': '2024-12-06 09:45:37'}\n",
      "Training started at 2024-12-06 09:45:37 with layers=(), solver=lbfgs, max_iter=5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KennethElong(KEEL)\\IdeaProjects\\firstPythonProject\\firstPyhtonProject\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed at 2024-12-06 09:56:09\n",
      "Evaluation started at 2024-12-06 09:56:09\n",
      "Evaluation completed at 2024-12-06 09:56:09\n",
      "Iteration Result: {'layers': (), 'solver': 'lbfgs', 'max_iter': 5000, 'train_accuracy (%)': '94.5232', 'test_accuracy (%)': '91.4857', 'training_time': '00:10:31', 'evaluation_time': '00:00:00', 'converged': 'No (Reached max_iter)', 'start_time': '2024-12-06 09:45:37', 'end_time': '2024-12-06 09:56:09'}\n",
      "Training started at 2024-12-06 09:56:09 with layers=(5,), solver=lbfgs, max_iter=500\n",
      "Training completed at 2024-12-06 09:56:11\n",
      "Evaluation started at 2024-12-06 09:56:11\n",
      "Evaluation completed at 2024-12-06 09:56:11\n",
      "Iteration Result: {'layers': (5,), 'solver': 'lbfgs', 'max_iter': 500, 'train_accuracy (%)': '11.2089', 'test_accuracy (%)': '11.4286', 'training_time': '00:00:02', 'evaluation_time': '00:00:00', 'converged': 'Yes', 'start_time': '2024-12-06 09:56:09', 'end_time': '2024-12-06 09:56:11'}\n",
      "Training started at 2024-12-06 09:56:11 with layers=(5,), solver=lbfgs, max_iter=2000\n",
      "Training completed at 2024-12-06 09:56:13\n",
      "Evaluation started at 2024-12-06 09:56:13\n",
      "Evaluation completed at 2024-12-06 09:56:13\n",
      "Iteration Result: {'layers': (5,), 'solver': 'lbfgs', 'max_iter': 2000, 'train_accuracy (%)': '11.2089', 'test_accuracy (%)': '11.4286', 'training_time': '00:00:02', 'evaluation_time': '00:00:00', 'converged': 'Yes', 'start_time': '2024-12-06 09:56:11', 'end_time': '2024-12-06 09:56:13'}\n",
      "Training started at 2024-12-06 09:56:13 with layers=(5,), solver=lbfgs, max_iter=5000\n",
      "Training completed at 2024-12-06 09:56:15\n",
      "Evaluation started at 2024-12-06 09:56:15\n",
      "Evaluation completed at 2024-12-06 09:56:15\n",
      "Iteration Result: {'layers': (5,), 'solver': 'lbfgs', 'max_iter': 5000, 'train_accuracy (%)': '11.2089', 'test_accuracy (%)': '11.4286', 'training_time': '00:00:02', 'evaluation_time': '00:00:00', 'converged': 'Yes', 'start_time': '2024-12-06 09:56:13', 'end_time': '2024-12-06 09:56:15'}\n",
      "Training started at 2024-12-06 09:56:15 with layers=(15,), solver=lbfgs, max_iter=500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KennethElong(KEEL)\\IdeaProjects\\firstPythonProject\\firstPyhtonProject\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed at 2024-12-06 09:57:44\n",
      "Evaluation started at 2024-12-06 09:57:44\n",
      "Evaluation completed at 2024-12-06 09:57:44\n",
      "Iteration Result: {'layers': (15,), 'solver': 'lbfgs', 'max_iter': 500, 'train_accuracy (%)': '51.4643', 'test_accuracy (%)': '51.4357', 'training_time': '00:01:28', 'evaluation_time': '00:00:00', 'converged': 'No (Reached max_iter)', 'start_time': '2024-12-06 09:56:15', 'end_time': '2024-12-06 09:57:44'}\n",
      "Training started at 2024-12-06 09:57:44 with layers=(15,), solver=lbfgs, max_iter=2000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 127\u001b[0m\n\u001b[0;32m    124\u001b[0m solver \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# Call the function\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m \u001b[43mtrain_and_evaluate_nn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayers_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayers_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43miterations_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miterations_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 51\u001b[0m, in \u001b[0;36mtrain_and_evaluate_nn\u001b[1;34m(layers_list, solver, iterations_list, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m     \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m max_iter:\n\u001b[0;32m     53\u001b[0m         converged \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo (Reached max_iter)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\KennethElong(KEEL)\\IdeaProjects\\firstPythonProject\\firstPyhtonProject\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\KennethElong(KEEL)\\IdeaProjects\\firstPythonProject\\firstPyhtonProject\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:751\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m    735\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and target(s) y.\u001b[39;00m\n\u001b[0;32m    736\u001b[0m \n\u001b[0;32m    737\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;124;03m        Returns a trained MLP model.\u001b[39;00m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincremental\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\KennethElong(KEEL)\\IdeaProjects\\firstPythonProject\\firstPyhtonProject\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:488\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# Run the LBFGS solver\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 488\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_lbfgs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeltas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintercept_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_units\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;66;03m# validate parameter weights\u001b[39;00m\n\u001b[0;32m    493\u001b[0m weights \u001b[38;5;241m=\u001b[39m chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoefs_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercepts_)\n",
      "File \u001b[1;32mc:\\Users\\KennethElong(KEEL)\\IdeaProjects\\firstPythonProject\\firstPyhtonProject\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:532\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._fit_lbfgs\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    530\u001b[0m     iprint \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 532\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loss_grad_lbfgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked_coef_inter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxfun\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_fun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeltas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintercept_grads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m _check_optimize_result(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m, opt_res, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter)\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_ \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[1;32mc:\\Users\\KennethElong(KEEL)\\IdeaProjects\\firstPythonProject\\firstPyhtonProject\\.venv\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:731\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    728\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    729\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 731\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    734\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    735\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\KennethElong(KEEL)\\IdeaProjects\\firstPythonProject\\firstPyhtonProject\\.venv\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:407\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    401\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\KennethElong(KEEL)\\IdeaProjects\\firstPythonProject\\firstPyhtonProject\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:343\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x(x)\n\u001b[1;32m--> 343\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32mc:\\Users\\KennethElong(KEEL)\\IdeaProjects\\firstPythonProject\\firstPyhtonProject\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:294\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 294\u001b[0m         fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_f:\n\u001b[0;32m    296\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[1;32mc:\\Users\\KennethElong(KEEL)\\IdeaProjects\\firstPythonProject\\firstPyhtonProject\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:20\u001b[0m, in \u001b[0;36m_wrapper_fun.<locals>.wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     16\u001b[0m ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32mc:\\Users\\KennethElong(KEEL)\\IdeaProjects\\firstPythonProject\\firstPyhtonProject\\.venv\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:79\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     78\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32mc:\\Users\\KennethElong(KEEL)\\IdeaProjects\\firstPythonProject\\firstPyhtonProject\\.venv\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:73\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 73\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\KennethElong(KEEL)\\IdeaProjects\\firstPythonProject\\firstPyhtonProject\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:281\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._loss_grad_lbfgs\u001b[1;34m(self, packed_coef_inter, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the MLP loss function and its corresponding derivatives\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;124;03mwith respect to the different parameters given in the initialization.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;124;03mgrad : array-like, shape (number of nodes of all layers,)\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unpack(packed_coef_inter)\n\u001b[1;32m--> 281\u001b[0m loss, coef_grads, intercept_grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backprop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeltas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintercept_grads\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m grad \u001b[38;5;241m=\u001b[39m _pack(coef_grads, intercept_grads)\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss, grad\n",
      "File \u001b[1;32mc:\\Users\\KennethElong(KEEL)\\IdeaProjects\\firstPythonProject\\firstPyhtonProject\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:326\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._backprop\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    323\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# Forward propagate\u001b[39;00m\n\u001b[1;32m--> 326\u001b[0m activations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m# Get loss\u001b[39;00m\n\u001b[0;32m    329\u001b[0m loss_func_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[1;32mc:\\Users\\KennethElong(KEEL)\\IdeaProjects\\firstPythonProject\\firstPyhtonProject\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:173\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._forward_pass\u001b[1;34m(self, activations)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# Iterate over the hidden layers\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers_ \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 173\u001b[0m     activations[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoefs_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m     activations[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercepts_[i]\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;66;03m# For the hidden layers\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\KennethElong(KEEL)\\IdeaProjects\\firstPythonProject\\firstPyhtonProject\\.venv\\Lib\\site-packages\\sklearn\\utils\\extmath.py:208\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    205\u001b[0m     ret \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m b\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m--> 208\u001b[0m     \u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    212\u001b[0m ):\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\KennethElong(KEEL)\\IdeaProjects\\firstPythonProject\\firstPyhtonProject\\.venv\\Lib\\site-packages\\scipy\\sparse\\_base.py:1335\u001b[0m, in \u001b[0;36missparse\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A namespace class to separate sparray from spmatrix\"\"\"\u001b[39;00m\n\u001b[0;32m   1332\u001b[0m sparray\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m _spbase\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\n\u001b[1;32m-> 1335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21missparse\u001b[39m(x):\n\u001b[0;32m   1336\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Is `x` of a sparse array or sparse matrix type?\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m \n\u001b[0;32m   1338\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, _spbase)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# File path for saving results\n",
    "file_path = \"full_dataset_results.csv\"\n",
    "\n",
    "# Function to format timestamps (start and end)\n",
    "def format_timestamp(seconds=None):\n",
    "    \"\"\"Format epoch time to YYYY-MM-DD HH:MM:SS.\"\"\"\n",
    "    if seconds is None:\n",
    "        seconds = time.time()\n",
    "    return datetime.fromtimestamp(seconds).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Function to format durations in hh:mm:ss\n",
    "def format_duration(seconds):\n",
    "    \"\"\"Convert duration in seconds to hh:mm:ss format.\"\"\"\n",
    "    hours, remainder = divmod(int(seconds), 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return f\"{hours:02}:{minutes:02}:{seconds:02}\"\n",
    "\n",
    "# Function to append results to the CSV file\n",
    "def append_result_to_csv(result, file_path):\n",
    "    \"\"\"Append a single result row to the CSV file.\"\"\"\n",
    "    result_df = pd.DataFrame([result])\n",
    "    if not os.path.exists(file_path):\n",
    "        result_df.to_csv(file_path, index=False)\n",
    "    else:\n",
    "        existing_df = pd.read_csv(file_path)\n",
    "        updated_df = pd.concat([existing_df, result_df], ignore_index=True)\n",
    "        updated_df.to_csv(file_path, index=False)\n",
    "\n",
    "# Training and evaluation function\n",
    "def train_and_evaluate_nn(layers_list, solver, iterations_list, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Train and evaluate a neural network.\"\"\"\n",
    "    for layers in layers_list:\n",
    "        for max_iter in iterations_list:\n",
    "            try:\n",
    "                # Log start time\n",
    "                start_train = time.time()\n",
    "                start_timestamp = format_timestamp(start_train)\n",
    "                print(f\"Training started at {start_timestamp} with layers={layers}, solver={solver}, max_iter={max_iter}\")\n",
    "\n",
    "                # Initialize NN model\n",
    "                nn = MLPClassifier(hidden_layer_sizes=layers, solver=solver, max_iter=max_iter, random_state=11)\n",
    "\n",
    "                # Train model\n",
    "                try:\n",
    "                    nn.fit(X_train, y_train)\n",
    "                    if nn.n_iter_ >= max_iter:\n",
    "                        converged = \"No (Reached max_iter)\"\n",
    "                    else:\n",
    "                        converged = \"Yes\"\n",
    "                except Exception as train_error:\n",
    "                    converged = f\"No (Error: {train_error})\"\n",
    "                    print(f\"Training failed: {train_error}\")\n",
    "                    train_acc = \"N/A\"\n",
    "                    test_acc = \"N/A\"\n",
    "                else:\n",
    "                    train_acc = nn.score(X_train, y_train) * 100\n",
    "                    test_acc = nn.score(X_test, y_test) * 100\n",
    "\n",
    "                end_train = time.time()\n",
    "                end_timestamp = format_timestamp(end_train)\n",
    "                training_duration = format_duration(end_train - start_train)\n",
    "                print(f\"Training completed at {end_timestamp}\")\n",
    "\n",
    "                # Evaluate model\n",
    "                start_eval = time.time()\n",
    "                print(f\"Evaluation started at {format_timestamp(start_eval)}\")\n",
    "                if converged.startswith(\"Yes\"):\n",
    "                    evaluation_duration = \"00:00:00\"  # lbfgs solver evaluates implicitly during training\n",
    "                else:\n",
    "                    evaluation_duration = format_duration(time.time() - start_eval)\n",
    "\n",
    "                print(f\"Evaluation completed at {format_timestamp(time.time())}\")\n",
    "\n",
    "                # Record results\n",
    "                result = {\n",
    "                    \"layers\": layers,\n",
    "                    \"solver\": solver,\n",
    "                    \"max_iter\": max_iter,\n",
    "                    \"train_accuracy (%)\": f\"{train_acc:.4f}\" if train_acc != \"N/A\" else \"N/A\",\n",
    "                    \"test_accuracy (%)\": f\"{test_acc:.4f}\" if test_acc != \"N/A\" else \"N/A\",\n",
    "                    \"training_time\": training_duration,\n",
    "                    \"evaluation_time\": evaluation_duration,\n",
    "                    \"converged\": converged,\n",
    "                    \"start_time\": start_timestamp,\n",
    "                    \"end_time\": end_timestamp\n",
    "                }\n",
    "\n",
    "                # Print the result of the current iteration\n",
    "                print(f\"Iteration Result: {result}\")\n",
    "\n",
    "                # Append the result to the CSV\n",
    "                append_result_to_csv(result, file_path)\n",
    "\n",
    "            except Exception as error:\n",
    "                print(f\"An error occurred during training with layers={layers} and max_iter={max_iter}: {error}\")\n",
    "                continue  # Move on to the next iteration\n",
    "\n",
    "# Example Usage\n",
    "# Assume X_train, X_test, y_train, y_test are already loaded and split elsewhere\n",
    "# Define parameters\n",
    "layers_list = [\n",
    "    (),  # No hidden layers\n",
    "    (5,),  # 1 layer, 5 neurons\n",
    "    (15,),  # 1 layer, 15 neurons\n",
    "    (5, 5),  # 2 layers, 5 neurons each\n",
    "    (10, 5),  # 2 layers, 10 neurons in first, 5 in second\n",
    "    (15, 15),  # 2 layers, 15 neurons each\n",
    "    (5, 5, 5),  # 3 layers, 5 neurons each\n",
    "    # (10,),  # 1 layer, 10 neurons (Commented out)\n",
    "    # (20,),  # 1 layer, 20 neurons (Commented out)\n",
    "    # (10, 10, 5),  # 3 layers, 10 neurons each in the first two layers, 5 in the third\n",
    "    # (10, 10, 10),  # 3 layers, 10 neurons each\n",
    "    (15, 15, 15),  # 3 layers, 15 neurons each\n",
    "    # (5, 5, 5, 5),  # 4 layers, 5 neurons each (Commented out)\n",
    "    (10, 10, 10, 10),  # 4 layers, 10 neurons each\n",
    "]\n",
    "iterations_list = [500, 2000, 5000]\n",
    "solver = \"lbfgs\"\n",
    "\n",
    "# Call the function\n",
    "train_and_evaluate_nn(\n",
    "    layers_list=layers_list,\n",
    "    solver=solver,\n",
    "    iterations_list=iterations_list,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below build a NN model with 4 layers, 10 nodes and 5000 in max iterations and makes a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exercise: Using `sklearn.metrics.confusion_matrix` you can get an overview of all combinations of true and predicted labels (\n",
    "# see p. 298-299 in MÃ¼ller & Guido). What does this tell you about which digits are easy, and which ones are difficult to recognize, and which ones are most easily confused?\n",
    "\n",
    "## Building a NN with 4 layers and 10 nodes, using relu and lbfgs and 5000 iterations\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the configuration\n",
    "layers = (10, 10, 10, 10)\n",
    "activation = \"relu\"\n",
    "solver = \"lbfgs\"\n",
    "max_iter = 5000\n",
    "\n",
    "def build_and_evaluate_nn(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # Initialize the model\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=layers,\n",
    "        activation=activation,\n",
    "        solver=solver,\n",
    "        max_iter=max_iter,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    print(f\"Training the model with layers={layers}, activation={activation}, solver={solver}, max_iter={max_iter}\")\n",
    "    try:\n",
    "        model.fit(X_train, y_train)\n",
    "        print(\"Training completed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during training: {e}\")\n",
    "        return\n",
    "\n",
    "    # Generate predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Display the confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f\"Confusion Matrix for Model Configuration: {layers}, {activation}, {solver}, {max_iter}\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assume X_train, X_test, y_train, and y_test are already defined.\n",
    "# Uncomment the line below to run the function with your dataset:\n",
    "# build_and_evaluate_nn(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Iteration 1, loss = 0.29130293\n",
      "Iteration 2, loss = 0.10562392\n",
      "Iteration 3, loss = 0.06646595\n",
      "Iteration 4, loss = 0.04825473\n",
      "Iteration 5, loss = 0.03408653\n",
      "Iteration 6, loss = 0.02480841\n",
      "Iteration 7, loss = 0.01772750\n",
      "Iteration 8, loss = 0.01742728\n",
      "Iteration 9, loss = 0.01654215\n",
      "Iteration 10, loss = 0.01820463\n",
      "Iteration 11, loss = 0.01834300\n",
      "Iteration 12, loss = 0.00950696\n",
      "Iteration 13, loss = 0.00726776\n",
      "Iteration 14, loss = 0.01606887\n",
      "Iteration 15, loss = 0.01653703\n",
      "Iteration 16, loss = 0.00860087\n",
      "Iteration 17, loss = 0.01265896\n",
      "Iteration 18, loss = 0.00535333\n",
      "Iteration 19, loss = 0.00692815\n",
      "Iteration 20, loss = 0.01181867\n",
      "Iteration 21, loss = 0.00791213\n",
      "Iteration 22, loss = 0.00428055\n",
      "Iteration 23, loss = 0.00395473\n",
      "Iteration 24, loss = 0.01056394\n",
      "Iteration 25, loss = 0.01230655\n",
      "Iteration 26, loss = 0.00623483\n",
      "Iteration 27, loss = 0.01067754\n",
      "Iteration 28, loss = 0.00811398\n",
      "Iteration 29, loss = 0.01218561\n",
      "Iteration 30, loss = 0.00778644\n",
      "Iteration 31, loss = 0.00294577\n",
      "Iteration 32, loss = 0.00172613\n",
      "Iteration 33, loss = 0.00064773\n",
      "Iteration 34, loss = 0.00057673\n",
      "Iteration 35, loss = 0.00056452\n",
      "Iteration 36, loss = 0.00055669\n",
      "Iteration 37, loss = 0.00055030\n",
      "Iteration 38, loss = 0.00054467\n",
      "Iteration 39, loss = 0.00053923\n",
      "Iteration 40, loss = 0.00053385\n",
      "Iteration 41, loss = 0.00052839\n",
      "Iteration 42, loss = 0.00052267\n",
      "Iteration 43, loss = 0.00051652\n",
      "Iteration 44, loss = 0.00050965\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Training completed.\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1343\n",
      "           1       0.99      0.99      0.99      1600\n",
      "           2       0.97      0.97      0.97      1380\n",
      "           3       0.98      0.97      0.97      1433\n",
      "           4       0.97      0.98      0.97      1295\n",
      "           5       0.97      0.97      0.97      1273\n",
      "           6       0.98      0.99      0.98      1396\n",
      "           7       0.97      0.98      0.97      1503\n",
      "           8       0.96      0.96      0.96      1357\n",
      "           9       0.97      0.96      0.97      1420\n",
      "\n",
      "    accuracy                           0.98     14000\n",
      "   macro avg       0.98      0.98      0.98     14000\n",
      "weighted avg       0.98      0.98      0.98     14000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1323    1    2    0    0    2    6    4    5    0]\n",
      " [   1 1584    3    3    1    0    0    6    2    0]\n",
      " [   3    5 1341    5    5    2    1    7   10    1]\n",
      " [   0    1    8 1392    1   12    0    9    4    6]\n",
      " [   0    1    2    1 1266    1    4    3    3   14]\n",
      " [   1    1    0   11    4 1232   11    3   10    0]\n",
      " [   2    1    1    0    7    3 1378    0    4    0]\n",
      " [   3    2   11    1    5    2    0 1466    3   10]\n",
      " [   3    6    7    9    2    5    5    8 1304    8]\n",
      " [   5    2    2    5   16    5    0    8    9 1368]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = fetch_openml(name=\"mnist_784\", version=1, as_frame=False)\n",
    "X, y = mnist.data, mnist.target.astype(\"int\")\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the model configuration\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    max_iter=100,\n",
    "    batch_size=128,\n",
    "    alpha=0.0001,\n",
    "    random_state=42,\n",
    "    verbose=True  # Enable verbose to monitor convergence\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"Training completed.\")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next investigate the capability of the different learning approaches to find a good model, when we know that a very accurate model exists. For this, we add a 'cheat column' to our data: we add an additional column to the data matrix that simply contains a 0/1 encoding of the actual class label: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheatcol=np.array(mnist_bin_target) #making a copy of the original target array\n",
    "cheatcol[cheatcol==digit0]=0  #re-coding the two classes as 0s and 1s\n",
    "cheatcol[cheatcol==digit1]=1\n",
    "\n",
    "# The type of the target array is originally 'object' (the values '0','1',...,'9' are seen as categorical labels,\n",
    "# not as numbers). We now want to use the 0's and 1's as numbers: \n",
    "cheatcol=cheatcol.astype(float)\n",
    "\n",
    "cheatcol=np.reshape(cheatcol,[mnist_bin_data.shape[0],1]) #getting the dimensions right for the following .hstack operation to work ... \n",
    "mnist_bin_data_cheat = np.hstack((mnist_bin_data,cheatcol)) #appending the new column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All our candidate model types now are able, in principle, to construct a 100% accurate classifier for this data: we only have to 'learn' that only the last column in the data matters, and we can predict 'digit0' if we find a 0 in the last column and 'digit1' if we find a 1. All our SVM or NN network models would in principle be able to do just this, through a suitable setting of the SVM coefficients, respectively the NN weights.\n",
    "\n",
    "**Exercise 2:** \n",
    "\n",
    "**a** Describe, briefly, how the coefficients and weights of an SVM and NN model (with a suitably chosen number of layers) would have to be set, so that the resulting model is 100% accurate on this cheating data. Only consider the accuracy of the SVM or NN classifier defined by the coefficients/weights. You need not take into account that the SVM satisfies the max-margin objective, or that the NN minimizes its error function. This part of the exercise does not involve any Python code. Just give your answer in a short text.\n",
    "\n",
    "**b** Investigate how the accuracy of different SVM and NN classifiers improves in practice on this new dataset. Do you achieve 100% accuracy on the test set? If not, try to change the encoding in the cheat column: instead of representing digit1 with a 1, use a larger number, e.g. 250. Does that help? Why? This part of the exercise is in Python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** (Now back to the data without a cheating column!) Suppose you want to design a custom kernel function for the MNIST data that better captures the relevant properties of 'similarity' in this data than the generic 'rbf' or 'poly' kernels. Bear in mind that the data as seen by our classifiers and kernel functions just consists of arrays of length 784. \n",
    "\n",
    "Describe one or two ideas for defining such a kernel. You need not show that the kernel you propose actually is positive semi-definite (though as a bonus, you can try to provide some arguments for that). This is a text-only exercise -- no sklearn code required!\n",
    "\n",
    "If you are really curious, you can implement your kernel as a function, and use it as a custom kernel. See http://scikit-learn.org/stable/auto_examples/svm/plot_custom_kernel.html#sphx-glr-auto-examples-svm-plot-custom-kernel-py for an example of how that is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
